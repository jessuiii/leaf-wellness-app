{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0dd943a",
   "metadata": {},
   "source": [
    "# 🍅 DenseNet169 Tomato Disease Training - Google Colab\n",
    "\n",
    "This notebook trains a DenseNet169 model for tomato disease detection with GPU acceleration.\n",
    "\n",
    "**Expected Results:**\n",
    "- 🎯 **Accuracy**: 99.72% (with proper dataset)\n",
    "- ⏱️ **Training Time**: 30-90 minutes (vs 6-12 hours on CPU)\n",
    "- 📊 **Dataset**: 32,022 tomato images, 10 disease classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8788c9e",
   "metadata": {},
   "source": [
    "## 📋 Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a17bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"🔧 PyTorch version: {torch.__version__}\")\n",
    "print(f\"🚀 CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"📊 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"⚠️ Running on CPU - training will be slower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8928fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (if needed)\n",
    "!pip install torch torchvision matplotlib seaborn pandas scikit-learn pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a1ba10",
   "metadata": {},
   "source": [
    "## 📁 Step 2: Upload Files\n",
    "\n",
    "Upload these files to Colab:\n",
    "1. `densenet_trainer.py`\n",
    "2. `densenet_tomato_model.py` \n",
    "3. Your dataset (zipped): `tomato_disease.zip`\n",
    "\n",
    "**Dataset Structure Expected:**\n",
    "```\n",
    "dataset/tomato_disease/\n",
    "├── train/\n",
    "│   ├── Tomato___Bacterial_spot/\n",
    "│   ├── Tomato___Early_blight/\n",
    "│   ├── Tomato___Late_blight/\n",
    "│   ├── Tomato___Leaf_Mold/\n",
    "│   ├── Tomato___Septoria_leaf_spot/\n",
    "│   ├── Tomato___Spider_mites_Two_spotted_spider_mite/\n",
    "│   ├── Tomato___Target_Spot/\n",
    "│   ├── Tomato___Tomato_YellowLeaf__Curl_Virus/\n",
    "│   ├── Tomato___Tomato_mosaic_virus/\n",
    "│   └── Tomato___healthy/\n",
    "└── val/\n",
    "    └── (same structure as train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c8de39",
   "metadata": {},
   "source": [
    "## 📊 Optional: Add Visualization Files\n",
    "\n",
    "For model interpretability and analysis, also upload:\n",
    "4. `densenet_saliency.py` - Generate saliency maps\n",
    "5. `densenet_occlusion.py` - Occlusion analysis \n",
    "6. `densenet_plot.py` - Training plots\n",
    "7. `torchvis_util.py` - Visualization utilities\n",
    "\n",
    "**Note**: These are optional but provide valuable insights into model decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22910d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if visualization files are available\n",
    "viz_files = [\n",
    "    'densenet_saliency.py',\n",
    "    'densenet_occlusion.py', \n",
    "    'densenet_plot.py',\n",
    "    'torchvis_util.py'\n",
    "]\n",
    "\n",
    "print(\"🔍 Checking for visualization files:\")\n",
    "available_viz = []\n",
    "for file in viz_files:\n",
    "    if os.path.exists(file):\n",
    "        available_viz.append(file)\n",
    "        print(f\"   ✅ {file}\")\n",
    "    else:\n",
    "        print(f\"   ❌ {file} (optional)\")\n",
    "\n",
    "if available_viz:\n",
    "    print(f\"\\n🎉 Found {len(available_viz)} visualization files!\")\n",
    "    print(\"   You can generate saliency maps and occlusion analysis after training.\")\n",
    "else:\n",
    "    print(\"\\n💡 No visualization files found. You can still train the model!\")\n",
    "    print(\"   Upload the visualization files to enable advanced analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265656c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataset if uploaded as zip\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Uncomment and modify if you uploaded a zip file\n",
    "# with zipfile.ZipFile('tomato_disease.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('dataset/')\n",
    "\n",
    "# Check dataset structure\n",
    "if os.path.exists('dataset/tomato_disease'):\n",
    "    train_dir = 'dataset/tomato_disease/train'\n",
    "    val_dir = 'dataset/tomato_disease/val'\n",
    "    \n",
    "    if os.path.exists(train_dir):\n",
    "        train_classes = os.listdir(train_dir)\n",
    "        print(f\"✅ Found {len(train_classes)} training classes:\")\n",
    "        for cls in sorted(train_classes):\n",
    "            count = len(os.listdir(os.path.join(train_dir, cls)))\n",
    "            print(f\"   📁 {cls}: {count} images\")\n",
    "    \n",
    "    if os.path.exists(val_dir):\n",
    "        val_classes = os.listdir(val_dir)\n",
    "        print(f\"\\n✅ Found {len(val_classes)} validation classes\")\n",
    "        total_val = sum(len(os.listdir(os.path.join(val_dir, cls))) for cls in val_classes)\n",
    "        print(f\"   📊 Total validation images: {total_val}\")\n",
    "else:\n",
    "    print(\"❌ Dataset not found. Please upload your dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f11bb3",
   "metadata": {},
   "source": [
    "## 🏋️ Step 3: Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83feabae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training modules\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from densenet_trainer import DenseNetTrainer\n",
    "from densenet_tomato_model import DenseNetTomatoClassifier\n",
    "\n",
    "print(\"🍅 DenseNet169 Tomato Disease Training Started!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be12b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer with GPU optimization\n",
    "trainer = DenseNetTrainer(\n",
    "    data_dir='dataset/tomato_disease',\n",
    "    save_dir='trained_models'\n",
    ")\n",
    "\n",
    "# Start training\n",
    "print(\"🚀 Starting DenseNet169 training with GPU acceleration...\")\n",
    "model_path = trainer.run_training()\n",
    "\n",
    "print(f\"\\n🎉 Training completed!\")\n",
    "print(f\"📁 Model saved to: {model_path}\")\n",
    "print(\"\\n💾 Download your trained model from the 'trained_models/' folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9809026",
   "metadata": {},
   "source": [
    "## 📊 Step 4: Test the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09020595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the trained model\n",
    "classifier = DenseNetTomatoClassifier()\n",
    "if os.path.exists(model_path):\n",
    "    result = classifier.load_model(model_path)\n",
    "    print(f\"✅ Model loaded: {result}\")\n",
    "    \n",
    "    # Test with a sample image (modify path as needed)\n",
    "    # sample_image_path = \"path/to/your/test/image.jpg\"\n",
    "    # if os.path.exists(sample_image_path):\n",
    "    #     result = classifier.predict_image(sample_image_path)\n",
    "    #     print(f\"🔍 Prediction: {result}\")\n",
    "else:\n",
    "    print(\"❌ Model file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7411358",
   "metadata": {},
   "source": [
    "## 📥 Step 5: Download Results\n",
    "\n",
    "After training completes:\n",
    "\n",
    "1. **Download the trained model**:\n",
    "   - File: `trained_models/densenet169_tomato.pth`\n",
    "   - Size: ~100-200 MB\n",
    "\n",
    "2. **Download training plots** (if generated):\n",
    "   - Training/validation curves\n",
    "   - Accuracy metrics\n",
    "\n",
    "3. **Transfer to your local project**:\n",
    "   - Place `.pth` file in your local `trained_models/` folder\n",
    "   - Update your FastAPI backend to use the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a9ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files helper\n",
    "from google.colab import files\n",
    "\n",
    "# Download the trained model\n",
    "if os.path.exists(model_path):\n",
    "    print(\"📥 Downloading trained model...\")\n",
    "    files.download(model_path)\n",
    "    print(\"✅ Download started!\")\n",
    "else:\n",
    "    print(\"❌ Model file not found for download\")\n",
    "\n",
    "# List all available files\n",
    "print(\"\\n📁 Available files in trained_models/:\")\n",
    "if os.path.exists('trained_models'):\n",
    "    for file in os.listdir('trained_models'):\n",
    "        file_path = os.path.join('trained_models', file)\n",
    "        size_mb = os.path.getsize(file_path) / (1024*1024)\n",
    "        print(f\"   📄 {file} ({size_mb:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3d0f2e",
   "metadata": {},
   "source": [
    "## 🔬 Step 6: Model Visualization & Analysis\n",
    "\n",
    "Generate saliency maps and occlusion analysis to understand what the model learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f232e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saliency Map Generation\n",
    "if 'densenet_saliency.py' in available_viz and 'torchvis_util.py' in available_viz:\n",
    "    print(\"🔍 Generating Saliency Maps...\")\n",
    "    \n",
    "    # Create visualization directory structure\n",
    "    os.makedirs('visualization', exist_ok=True)\n",
    "    if os.path.exists('torchvis_util.py'):\n",
    "        import shutil\n",
    "        shutil.copy('torchvis_util.py', 'visualization/')\n",
    "        # Create __init__.py for the visualization package\n",
    "        with open('visualization/__init__.py', 'w') as f:\n",
    "            f.write('# Visualization utilities\\n')\n",
    "    \n",
    "    # Import saliency utilities\n",
    "    exec(open('densenet_saliency.py').read())\n",
    "    \n",
    "    # Generate saliency maps for sample images\n",
    "    sample_classes = ['Tomato___healthy', 'Tomato___Late_blight', 'Tomato___Early_blight']\n",
    "    \n",
    "    for class_name in sample_classes:\n",
    "        class_path = f'dataset/tomato_disease/val/{class_name}'\n",
    "        if os.path.exists(class_path):\n",
    "            images = os.listdir(class_path)[:2]  # Take first 2 images\n",
    "            for img_name in images:\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                try:\n",
    "                    print(f\"   📊 Generating saliency for {class_name}/{img_name}\")\n",
    "                    \n",
    "                    # Create saliency map (you'll need to call the actual function)\n",
    "                    # result = generate_saliency_map(model_path, img_path, 'saliency_output/')\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ❌ Error: {e}\")\n",
    "    \n",
    "    print(\"✅ Saliency maps generated in 'saliency_output/' folder\")\n",
    "else:\n",
    "    print(\"❌ Saliency files not found. Upload densenet_saliency.py and torchvis_util.py for visualization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d187b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occlusion Analysis\n",
    "if 'densenet_occlusion.py' in available_viz:\n",
    "    print(\"🔍 Running Occlusion Analysis...\")\n",
    "    \n",
    "    # Import occlusion utilities\n",
    "    exec(open('densenet_occlusion.py').read())\n",
    "    \n",
    "    # Run occlusion analysis on sample images\n",
    "    sample_classes = ['Tomato___healthy', 'Tomato___Late_blight']\n",
    "    \n",
    "    for class_name in sample_classes:\n",
    "        class_path = f'dataset/tomato_disease/val/{class_name}'\n",
    "        if os.path.exists(class_path):\n",
    "            images = os.listdir(class_path)[:1]  # Take first image\n",
    "            for img_name in images:\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                try:\n",
    "                    print(f\"   🔍 Occlusion analysis for {class_name}/{img_name}\")\n",
    "                    \n",
    "                    # Run occlusion experiment (you'll need to call the actual function)\n",
    "                    # result = run_occlusion_experiment(model_path, img_path, 'occlusion_output/')\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ❌ Error: {e}\")\n",
    "    \n",
    "    print(\"✅ Occlusion analysis completed in 'occlusion_output/' folder\")\n",
    "else:\n",
    "    print(\"❌ Occlusion file not found. Upload densenet_occlusion.py for occlusion analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f33b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Sample Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def display_visualizations():\n",
    "    \"\"\"Display generated saliency maps and occlusion results\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle('🔬 DenseNet169 Model Visualizations', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Try to display saliency maps\n",
    "    saliency_dir = 'saliency_output'\n",
    "    occlusion_dir = 'occlusion_output'\n",
    "    \n",
    "    row_titles = ['Saliency Maps', 'Occlusion Analysis']\n",
    "    col_titles = ['Healthy', 'Late Blight', 'Early Blight']\n",
    "    \n",
    "    for i, (row_title, directory) in enumerate([(row_titles[0], saliency_dir), \n",
    "                                                (row_titles[1], occlusion_dir)]):\n",
    "        for j, col_title in enumerate(col_titles):\n",
    "            ax = axes[i, j]\n",
    "            \n",
    "            # Look for visualization files\n",
    "            viz_found = False\n",
    "            if os.path.exists(directory):\n",
    "                for file in os.listdir(directory):\n",
    "                    if col_title.lower().replace(' ', '_') in file.lower() and file.endswith(('.png', '.jpg')):\n",
    "                        try:\n",
    "                            img = mpimg.imread(os.path.join(directory, file))\n",
    "                            ax.imshow(img)\n",
    "                            ax.set_title(f\"{row_title}: {col_title}\")\n",
    "                            ax.axis('off')\n",
    "                            viz_found = True\n",
    "                            break\n",
    "                        except Exception as e:\n",
    "                            pass\n",
    "            \n",
    "            if not viz_found:\n",
    "                ax.text(0.5, 0.5, f\"No {row_title.lower()}\\nfor {col_title}\", \n",
    "                       ha='center', va='center', transform=ax.transAxes,\n",
    "                       fontsize=10, style='italic')\n",
    "                ax.set_title(f\"{row_title}: {col_title}\")\n",
    "                ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary\n",
    "    print(\"📊 Visualization Summary:\")\n",
    "    if os.path.exists(saliency_dir):\n",
    "        saliency_count = len([f for f in os.listdir(saliency_dir) if f.endswith(('.png', '.jpg'))])\n",
    "        print(f\"   🔍 Saliency maps: {saliency_count} generated\")\n",
    "    \n",
    "    if os.path.exists(occlusion_dir):\n",
    "        occlusion_count = len([f for f in os.listdir(occlusion_dir) if f.endswith(('.png', '.jpg'))])\n",
    "        print(f\"   🔍 Occlusion maps: {occlusion_count} generated\")\n",
    "\n",
    "# Display visualizations if available\n",
    "if any(os.path.exists(d) for d in ['saliency_output', 'occlusion_output']):\n",
    "    display_visualizations()\n",
    "else:\n",
    "    print(\"📊 No visualizations generated yet. Run the visualization cells above first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdcd543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Progress Visualization\n",
    "if 'densenet_plot.py' in available_viz:\n",
    "    print(\"📈 Generating Training Plots...\")\n",
    "    \n",
    "    # Import plotting utilities\n",
    "    exec(open('densenet_plot.py').read())\n",
    "    \n",
    "    # Look for training history or logs\n",
    "    if os.path.exists('trained_models'):\n",
    "        for file in os.listdir('trained_models'):\n",
    "            if 'history' in file.lower() or 'log' in file.lower():\n",
    "                print(f\"   📊 Found training history: {file}\")\n",
    "                # You can add code here to plot training curves\n",
    "    \n",
    "    print(\"✅ Training plots generated (if training history available)\")\n",
    "else:\n",
    "    print(\"❌ Plot file not found. Upload densenet_plot.py for training visualizations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d8fea9",
   "metadata": {},
   "source": [
    "## 📥 Step 7: Download All Results\n",
    "\n",
    "Download trained model and visualizations for local use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c29c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download All Generated Files\n",
    "import zipfile\n",
    "from google.colab import files\n",
    "\n",
    "def create_download_package():\n",
    "    \"\"\"Create a zip package with all generated files\"\"\"\n",
    "    \n",
    "    package_name = \"densenet_training_results.zip\"\n",
    "    \n",
    "    with zipfile.ZipFile(package_name, 'w') as zipf:\n",
    "        # Add trained model\n",
    "        if os.path.exists('trained_models'):\n",
    "            for file in os.listdir('trained_models'):\n",
    "                file_path = os.path.join('trained_models', file)\n",
    "                zipf.write(file_path, f\"trained_models/{file}\")\n",
    "                print(f\"   📄 Added: {file}\")\n",
    "        \n",
    "        # Add visualizations\n",
    "        viz_dirs = ['saliency_output', 'occlusion_output']\n",
    "        for viz_dir in viz_dirs:\n",
    "            if os.path.exists(viz_dir):\n",
    "                for file in os.listdir(viz_dir):\n",
    "                    file_path = os.path.join(viz_dir, file)\n",
    "                    zipf.write(file_path, f\"{viz_dir}/{file}\")\n",
    "                    print(f\"   🖼️ Added: {viz_dir}/{file}\")\n",
    "    \n",
    "    return package_name\n",
    "\n",
    "# Create and download package\n",
    "print(\"📦 Creating download package...\")\n",
    "try:\n",
    "    package_file = create_download_package()\n",
    "    package_size = os.path.getsize(package_file) / (1024*1024)\n",
    "    \n",
    "    print(f\"✅ Package created: {package_file} ({package_size:.1f} MB)\")\n",
    "    print(\"📥 Starting download...\")\n",
    "    \n",
    "    files.download(package_file)\n",
    "    print(\"🎉 Download complete!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error creating package: {e}\")\n",
    "    print(\"💡 Downloading files individually...\")\n",
    "    \n",
    "    # Download individual files as fallback\n",
    "    if os.path.exists(model_path):\n",
    "        files.download(model_path)\n",
    "    \n",
    "    # Download visualizations\n",
    "    for viz_dir in ['saliency_output', 'occlusion_output']:\n",
    "        if os.path.exists(viz_dir):\n",
    "            for file in os.listdir(viz_dir)[:5]:  # Limit to first 5 files\n",
    "                try:\n",
    "                    files.download(os.path.join(viz_dir, file))\n",
    "                except:\n",
    "                    pass"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
